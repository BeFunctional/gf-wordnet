# -*- mode:org -*-
#+TITLE: how to bootstrap a new concrete WordNet grammar

If your target language has a [[https://github.com/grammaticalframework/wide-coverage][Translate grammar]] but no WordNet, use
the =migrate.hs= script to bootstrap it, and you are done. If your
language has both, it is better to bootstrap the new concrete using
WordNet. Else keep on reading.

Our end goal is to map GF abstract =fun= names to lemmas in our target
language. We do this by matching them by their WordNet synsets, so
this method is only suitable for languages which have a (hopefully
decently-sized) WordNet available in the format used by the [[http://compling.hss.ntu.edu.sg/omw/][OMW]]. This
grammar uses the synsets from WordNet 3.1 while the OMW uses WordNet
3.0, so we need to do a little conversion before we are ready. The
conversion is done using standard terminal utilities (GNU versions).

* WN3.0->WN3.1 mapping
The file =wn30map31.txt= maps the synsets from WordNet 3.0 to WordNet
3.1. We adapt its format so that it becomes =sense3.0 sense3.1=:
: tail -n +9  wn30map31.txt | sed -Ee 's/^([anrv])   ([0-9]+)        ([0-9]+)$/\2-\1 \3-\1/p' | sort -u -k1 > wn30map31.synsets.txt

* obtain translation predictions
Not all words in a given synset in English are equally good
translations for any word in your target language's synset. Krasimir
Angelov developed an heuristic algorithm to decide automatically which
translation pairs seem to be good matches. You can find the details in
this [[http://www.aclweb.org/anthology/W16-4504][paper]], and run the algorithm following the [[https://github.com/GrammaticalFramework/wide-coverage/blob/master/translator/classify.hs][built-in instructions]],
which should yield you a =predictions.tsv= file, from which we obtain
the =good-predictions.tsv= by filtering the translations the algorithm
deemed good (the ones whose last column value is =True=). We then have
to add the 3.1 synsets to the translation pairs:
#+BEGIN_SRC sh
  sort -k1 -u good-predictions.tsv > sorted-predictions.tsv
  join -t '       ' wn30map31.synsets.txt sorted-predictions.tsv | sort -u -k2 > predictions-synsets.tsv
#+END_SRC

* obtain GF abstract names
The next step is to match the translation pairs with their GF abstract
function names. This can be done because each =fun= in =WordNet.gf=
contains its respective synset.
#+BEGIN_SRC sh
  # extract fun names and their synsets, then sort by synset.
  â€‹sed -Ee 's/^fun +([^ ]+)[^-]+--+ +([0-9]+-[nvar]).*/\2       \1/' ../WordNet.gf | grep -E '^[0-9].*' | sort -k 1 > synset-fun.txt
  # join by synset
  join -t '	' -1 1 -2 2 synset-fun.txt predictions-synsets.tsv > fun-lang.tsv
  # cut to what we want (GF fun name and lemma in target language) and merge lines with the same fun name
  cut -d '	' -f 2,5 fun-lang.tsv  | sort -u -k1 | awk 'NF>1{a[$1] = a[$1]"	"$2};END{for(i in a)print i""a[i]}' | sort -u -k1 > fun-lemmas.tsv
#+END_SRC
now each line of =fun-lemmas.tsv= should be tab separated values,
where the first value is the GF =fun= name, and the rest are the
lemmas of its possible linearizations.

* building WordNet***
You now have several options to obtain your target language's concrete
=WordNet= module. If your target language already has some large
dictionary module in GF, you can map its linearizations to the =fun=
names by matching lemmas. Another option is to apply smart paradigms
to these lemmas in order to obtain tentative linearizations. Ideally
you'll have a large scale morphological resource which you can then
check the GF linearizations against.

=MakeDictFromLemmas.hs= can build a rudimentary WordNet concrete by
using the simplest smart paradigms. This will require extensive manual
revision afterwards. It takes two filepaths as arguments, the first is
a file in the same format as =fun-lemmas.tsv=, and the other is the
name of the output file. You can customize the output language name
and the functions to be applied (to some extent).
